{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffa4744",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas numpy scikit-learn matplotlib seaborn xgboost joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad90d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# 1. IMPORT LIBRARIES\n",
    "# ======================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Set visual style for graphs\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "print(\"‚úÖ Libraries Imported Successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adffe4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# 2. LOAD DATA (LOCAL FILES)\n",
    "# ======================================================\n",
    "print(\"\\nüìÇ Loading Datasets...\")\n",
    "df_list = []\n",
    "\n",
    "# --- Load SMS Data ---\n",
    "try:\n",
    "    sms_files = [\"sms/train.csv\", \"sms/test.csv\", \"sms/valid.csv\"]\n",
    "    for f in sms_files:\n",
    "        temp_df = pd.read_csv(f)\n",
    "        df_list.append(temp_df)\n",
    "    \n",
    "    print(\"   -> SMS files loaded.\")\n",
    "except Exception as e:\n",
    "    print(f\"   ‚ö†Ô∏è Error loading SMS: {e}\")\n",
    "\n",
    "# --- Load Email Data ---\n",
    "try:\n",
    "    email_df = pd.read_json(\"phishing_email.jsonl\", lines=True)\n",
    "    if 'prompt' in email_df.columns:\n",
    "        email_df = email_df.rename(columns={'prompt': 'text'})\n",
    "    df_list.append(email_df[['text', 'label']])\n",
    "    print(\"   -> Email file loaded.\")\n",
    "except Exception as e:\n",
    "    print(f\"   ‚ö†Ô∏è Error loading Email: {e}\")\n",
    "\n",
    "# --- Combine & Clean ---\n",
    "df_final = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Standardize Labels (Ensure 0 = Safe, 1 = Phishing)\n",
    "# Some datasets use strings 'ham'/'spam', others use ints 0/1\n",
    "if df_final['label'].dtype == 'object':\n",
    "    df_final['label'] = df_final['label'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "df_final.dropna(inplace=True)\n",
    "df_final['label'] = df_final['label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82181e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# 3. DATA STATISTICS & GRAPHS\n",
    "# ======================================================\n",
    "total = len(df_final)\n",
    "safe = len(df_final[df_final['label'] == 0])\n",
    "phish = len(df_final[df_final['label'] == 1])\n",
    "\n",
    "print(f\"\\nüìä DATASET STATISTICS\")\n",
    "print(f\"----------------------\")\n",
    "print(f\"Total Samples: {total}\")\n",
    "print(f\"Safe (0):      {safe} ({(safe/total)*100:.1f}%)\")\n",
    "print(f\"Phishing (1):  {phish} ({(phish/total)*100:.1f}%)\")\n",
    "\n",
    "# --- Graph 1: Class Distribution ---\n",
    "plt.figure(figsize=(8, 5))\n",
    "ax = sns.countplot(x='label', data=df_final, palette=['#2ecc71', '#e74c3c'])\n",
    "plt.title('Distribution: Safe vs Phishing', fontsize=15)\n",
    "plt.xticks([0, 1], ['Safe Messages', 'Phishing Attempts'])\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Add counts on bars\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{int(p.get_height())}', (p.get_x()+0.35, p.get_height()+100), fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5ecec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# 4. TEXT PRE-PROCESSING\n",
    "# ======================================================\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    # Mask URLs to a generic token so model learns \"Presence of Link\" = Bad\n",
    "    text = re.sub(r'http\\S+', 'http_token', text)\n",
    "    text = re.sub(r'www\\S+', 'http_token', text)\n",
    "    # Keep currency symbols ($ ¬£ ‚Ç¨) as they are strong indicators\n",
    "    text = re.sub(r'[^a-z0-9!?$¬£‚Ç¨ ]', '', text) \n",
    "    return text\n",
    "\n",
    "print(\"\\nüßπ Cleaning Text Data...\")\n",
    "df_final['clean_text'] = df_final['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ff9ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# 5. BUILD VOTING ENSEMBLE MODEL\n",
    "# ======================================================\n",
    "print(\"‚öôÔ∏è Building Voting Ensemble Model...\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_final['clean_text'], \n",
    "    df_final['label'], \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=df_final['label']\n",
    ")\n",
    "\n",
    "# Define the 3 Classifiers\n",
    "clf1 = RandomForestClassifier(n_estimators=150, random_state=42, n_jobs=-1, class_weight='balanced')\n",
    "clf2 = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42, n_jobs=-1)\n",
    "clf3 = LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced')\n",
    "\n",
    "# Combine into Voting Classifier (Soft Voting = Average Probabilities)\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('rf', clf1), ('xgb', clf2), ('lr', clf3)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# Create Pipeline with TF-IDF\n",
    "pipeline = Pipeline([\n",
    "    # ngram_range=(1,3) means it looks at phrases up to 3 words long\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english', max_features=12000, ngram_range=(1, 3))),\n",
    "    ('ensemble', voting_clf)\n",
    "])\n",
    "\n",
    "print(\"üöÄ Training Model... (This is robust, give it a moment)\")\n",
    "pipeline.fit(X_train, y_train)\n",
    "print(\"‚úÖ Training Complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b3ada3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# 6. EVALUATION & ACCURACY GRAPHS\n",
    "# ======================================================\n",
    "y_pred = pipeline.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"üèÜ FINAL MODEL ACCURACY: {acc:.4f} ({acc*100:.2f}%)\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Safe', 'Phishing']))\n",
    "\n",
    "# --- Graph 2: Confusion Matrix ---\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(7, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', linewidths=1, linecolor='black',\n",
    "            xticklabels=['Predicted Safe', 'Predicted Phishing'],\n",
    "            yticklabels=['Actual Safe', 'Actual Phishing'])\n",
    "plt.title('Confusion Matrix (Where did the model make mistakes?)', fontsize=14)\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486def7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# 7. SAVE MODEL & TEST\n",
    "# ======================================================\n",
    "model_filename = \"best_phishing_model.pkl\"\n",
    "joblib.dump(pipeline, model_filename)\n",
    "print(f\"\\nüíæ Model saved successfully to: {model_filename}\")\n",
    "\n",
    "def live_test(text):\n",
    "    clean = clean_text(text)\n",
    "    pred = pipeline.predict([clean])[0]\n",
    "    prob = pipeline.predict_proba([clean])[0]\n",
    "    \n",
    "    if pred == 1:\n",
    "        print(f\"üî¥ PHISHING ({prob[1]*100:.2f}%): '{text}'\")\n",
    "    else:\n",
    "        print(f\"üü¢ SAFE ({prob[0]*100:.2f}%): '{text}'\")\n",
    "\n",
    "print(\"\\n--- üß™ LIVE TEST EXAMPLES ---\")\n",
    "live_test(\"Hey, can we meet for lunch?\")\n",
    "live_test(\"URGENT: Your bank account is locked. Update immediately at http://fake-bank.com\")\n",
    "live_test(\"You have won a $1000 prize! Click here to claim.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
